{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission for<br>\n",
    "Exercise task 9<br>\n",
    "of UTU course TKO_8964-3006<br>\n",
    "Textual Data Analysis<br>\n",
    "by Botond Ortutay<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercice, we will work on relation extraction part of the [Bacteria Biotope task at BioNLP Open Shared Tasks 2019](https://aclanthology.org/D19-5719/). Although the original task in the paper is more complicated (covers more relation types), here we have simplified the dataset, so that you can focus on extracting binary relations with GPT. \n",
    "\n",
    "The task is a binary relation extraction, with three entity types:\n",
    " - Microorganism (e.g. bacteria)\n",
    " - Habitat (e.g. milk, cheese, etc)\n",
    " - Geographical (e.g. Europe)\n",
    "\n",
    "and one binary relaiton type: *Lives_in* in the form of:\n",
    " - *Lives_in*(Microorganism , Habitat)\n",
    " - *Lives_in*(Microorganism , Geographical)\n",
    "\n",
    "Therefore, prediction outcome is **Positive** if the sentence states that the Microorganism lives in the mentioned Habitat/Geographical and **Negative**, otherwise. \n",
    "\n",
    "For example:\n",
    " - **Salmonella** was noticed in **raw chicken**. --> Positive --> Lives_in (Salmonella, raw chicken)\n",
    " - **Salmonella** was not noticed in **cooked chicken**. --> Negative\n",
    "\n",
    "You are provided with a Colab [notebook](https://github.com/TurkuNLP/textual-data-analysis-course/blob/main/tda_2025_Ex9_2025_Rel_withGPT.ipynb) that already covers about 80% of the work. Your task is to complete the remaining 20%. For example, code to download the data, generate candidate pairs, mark entity spans, and even prompting GPT to predict the labels for the examples are given. \n",
    "\n",
    "For using GPT, use the **api-key** that you were provided in **Exercise task 6**.\n",
    "\n",
    "First, familiarize yourself with the data and the code, and then complete the following tasks.\n",
    "\n",
    "**Task1**:\n",
    "\n",
    "Write a code that predicts the labels for all examples in `filtered_devel_examples` (there are 91 examples in this set) by asking the GPT model. You **must** use a `for` loop that packs **5 examples at-a-time** (in each iteration of the for loop), and passes to GPT, and predicts the labels for them at once. This is to keep GPT costs low (a real situation if you're going to work for a company). Then use `sklearn.metrics.precision_recall_fscore_support` to report precision, recall, and f1-score for the `filtered_devel_examples`. Do **NOT** give any example inputs to the GPT (**no few-shot learning in this step**).\n",
    "\n",
    "**Task2**:\n",
    "\n",
    "Now, include the two positive and negative sentence about Salmonella and chicken that I had mentioned, as examples in your prompts.\n",
    " - \"UID: UID_1000 Text = Salmonella was noticed in raw chicken. --> {'UID':'UID_1000', label = 'Positive'}\n",
    " - \"UID: UID_1001 Text = Salmonella was not noticed in coocked chicken. --> {'UID':'UID_1001', label = 'Negative'}\"\n",
    "\n",
    "and repeat the experiment, and report precision, recall, and f1-score. How the results have changed?\n",
    "\n",
    "**Task3**:\n",
    "\n",
    "3.1 Now **randomly** select 4 examples from the **training set** (you can take 2 positives, 2 negatives, or really sample randomly) and include them in your prompt, repeat the experiment, report precision, recall, and f1-score. How the results have changed?\n",
    "\n",
    "3.2 Repeat above experiment: Again, **randomly** sample 4 training examples and use them **instead** of the 4 previous examples. Have the results changed? **Why?**\n",
    "\n",
    "**IMPORTANT**: In order not to get a time-out error from GPT call, you can increase the timeout, **but also make sure you sample from smaller texts**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code from [colab notebook](https://github.com/TurkuNLP/textual-data-analysis-course/blob/main/tda_2025_Ex9_2025_Rel_withGPT.ipynb) (provided in instructions) (small modifications):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1G\u001b[27G[https://raw.githubusercontent.]\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JSaving 'bb4_converted_train.json'\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Gbb4_converted_train. 100% [=============================>]   74.24K    --.-KB/s\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JHTTP response 200  [https://raw.githubusercontent.com/TurkuNLP/textual-data-analysis-course/main/BB4_converted_train.json]\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Gbb4_converted_train. 100% [=============================>]   74.24K    --.-KB/s\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 1  Bytes: 74.24K [205.1]\u001b8\u001b[m\u001b[m\u001b[m\u001b[m\n",
      "\n",
      "\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1G\u001b[27G[https://raw.githubusercontent.]\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JSaving 'bb4_converted_devel.json'\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Gbb4_converted_devel. 100% [=============================>]   41.83K    --.-KB/s\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JHTTP response 200  [https://raw.githubusercontent.com/TurkuNLP/textual-data-analysis-course/main/BB4_converted_devel.json]\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Gbb4_converted_devel. 100% [=============================>]   41.83K    --.-KB/s\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 1  Bytes: 41.83K [99.13]\u001b8\u001b[m\u001b[m\u001b[m\u001b[m"
     ]
    }
   ],
   "source": [
    "#bash scripts here\n",
    "# downloading datasets\n",
    "!wget -O bb4_converted_train.json https://raw.githubusercontent.com/TurkuNLP/textual-data-analysis-course/main/BB4_converted_train.json\n",
    "!wget -O bb4_converted_devel.json https://raw.githubusercontent.com/TurkuNLP/textual-data-analysis-course/main/BB4_converted_devel.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files in:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training documents: 125\n",
      "development documents: 64\n"
     ]
    }
   ],
   "source": [
    "def read_json(file_name):\n",
    "  with open(file_name, \"rt\" , encoding = 'utf-8') as f:\n",
    "    data = json.load(f)\n",
    "  return data\n",
    "\n",
    "train = read_json(\"bb4_converted_train.json\")\n",
    "devel = read_json(\"bb4_converted_devel.json\")\n",
    "\n",
    "print(\"training documents:\" , len(train))\n",
    "print(\"development documents:\" , len(devel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploring dataformat:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['BB-rel-F-22177851-006', 'BB-rel-F-22177851-012', 'BB-rel-18845825', 'BB-rel-9526514', 'BB-rel-12970344', 'BB-rel-F-22177851-013', 'BB-rel-F-22177851-007', 'BB-rel-6143890', 'BB-rel-17237163', 'BB-rel-10738994', 'BB-rel-16990433', 'BB-rel-24678646', 'BB-rel-F-22177851-011', 'BB-rel-F-22177851-005', 'BB-rel-F-22177851-004', 'BB-rel-25634638', 'BB-rel-F-22177851-010', 'BB-rel-8607503', 'BB-rel-F-18524407-001', 'BB-rel-F-22177851-014', 'BB-rel-F-22177851-000', 'BB-rel-F-23290227-000', 'BB-rel-8347510', 'BB-rel-F-22177851-001', 'BB-rel-F-22177851-015', 'BB-rel-448557', 'BB-rel-F-18524407-000', 'BB-rel-14645268', 'BB-rel-11410343', 'BB-rel-21917915', 'BB-rel-F-22177851-003', 'BB-rel-F-22177851-017', 'BB-rel-9643457', 'BB-rel-F-22177851-002', 'BB-rel-16263187', 'BB-rel-F-25496341-009', 'BB-rel-6631408', 'BB-rel-24831788', 'BB-rel-2696427', 'BB-rel-F-25496341-008', 'BB-rel-19099664', 'BB-rel-F-23224222-009', 'BB-rel-F-23224222-008', 'BB-rel-16432479', 'BB-rel-25098305', 'BB-rel-24361838', 'BB-rel-24874563', 'BB-rel-9864452', 'BB-rel-607884', 'BB-rel-22834551', 'BB-rel-23908036', 'BB-rel-6107735', 'BB-rel-19175621', 'BB-rel-4329237', 'BB-rel-9798026', 'BB-rel-23855904', 'BB-rel-20073421', 'BB-rel-4105033', 'BB-rel-19396518', 'BB-rel-F-25496341-000', 'BB-rel-F-23224222-003', 'BB-rel-21924022', 'BB-rel-F-23224222-002', 'BB-rel-8997164', 'BB-rel-12781527', 'BB-rel-F-25496341-001', 'BB-rel-24198224', 'BB-rel-1016123', 'BB-rel-F-25496341-003', 'BB-rel-25562320', 'BB-rel-F-23224222-000', 'BB-rel-F-23224222-001', 'BB-rel-19501788', 'BB-rel-F-25496341-002', 'BB-rel-F-26678131-004', 'BB-rel-F-27020288-002', 'BB-rel-F-26678131-000', 'BB-rel-20148898', 'BB-rel-F-25496341-006', 'BB-rel-F-23224222-011', 'BB-rel-F-23224222-005', 'BB-rel-F-23224222-004', 'BB-rel-9255900', 'BB-rel-F-23224222-010', 'BB-rel-19622846', 'BB-rel-F-25496341-007', 'BB-rel-F-26678131-001', 'BB-rel-F-27020288-003', 'BB-rel-19049879', 'BB-rel-F-27020288-001', 'BB-rel-11437594', 'BB-rel-F-26678131-003', 'BB-rel-F-25496341-005', 'BB-rel-F-25496341-011', 'BB-rel-F-23224222-006', 'BB-rel-F-23224222-012', 'BB-rel-F-23224222-013', 'BB-rel-F-23224222-007', 'BB-rel-8532424', 'BB-rel-F-25496341-010', 'BB-rel-F-25496341-004', 'BB-rel-F-26678131-002', 'BB-rel-F-27020288-000', 'BB-rel-20005916', 'BB-rel-15358511', 'BB-rel-F-22177851-018', 'BB-rel-17687514', 'BB-rel-10658649', 'BB-rel-4328756', 'BB-rel-F-22177851-019', 'BB-rel-16436701', 'BB-rel-23702192', 'BB-rel-3074181', 'BB-rel-12728302', 'BB-rel-19075662', 'BB-rel-9564489', 'BB-rel-F-22177851-009', 'BB-rel-F-22177851-021', 'BB-rel-9535771', 'BB-rel-F-22177851-020', 'BB-rel-F-22177851-008', 'BB-rel-8358765', 'BB-rel-F-22177851-022', 'BB-rel-21498521', 'BB-rel-F-22177851-023'])\n",
      "('text', 'On the other hand, methylthiobutyrate, methyl ester octanoic acid, \\nbenzeneacetaldehyde and 3-heptanone were only found in the community \\nwith P. celer.\\n')\n",
      "('entities', {'T1': {'type': 'Habitat', 'offsets': [[127, 151]], 'text': 'community  with P. celer'}, 'T2': {'type': 'Microorganism', 'offsets': [[143, 151]], 'text': 'P. celer'}})\n",
      "('relations', {'R1': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T1', 'e1_type': 'Microorganism', 'e2_type': 'Location'}})\n"
     ]
    }
   ],
   "source": [
    "print (train.keys())\n",
    "train_doc_id = \"BB-rel-F-22177851-012\"\n",
    "for item in train[train_doc_id].items():\n",
    "  print (item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each document in the training or development set has a key, and it is a python dictionary, with \"text\" , \"entities\" , and \"relations\".\n",
    " - Entities have ids, starting with \"T\", type, and begining and end offsets in the text. **Some entities have multiple spans.**\n",
    " - Relations are also have ids, starting with \"R\" , and two arguments (entities). The first argument (e1), is always a Microorganism, and the second argument (e2) is either a \"Habitat\", or a \"Geographical\" location.\n",
    "\n",
    "**because this is manually annotated dataset, only positive pairs are annotated. We can generate all candidate pairs, and those that are annotated, are Positive examples, and those which we cannot find in the relations part, are the negative examples.**\n",
    "\n",
    "In the above example, there is only one Habitat, one Microorganism, and one (Positive) relation between them.\n",
    "\n",
    "**But a document can have more than two entities and relations. Here is an example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT= The strain S3 + and its protease-negative variant S3-, assigned to Lactococcus lactis sp. lactis, was used for cheese-making. The 11 microorganisms that composed the model community included seven bacteria — Lactobacillus casei FH1, Arthrobacter arilaitensis Re117, Corynebacterium casei Mu120, C. flavescens Mu128, C. variabile Mu129, Staphylococcus xylosus Com1 and S. equorum Mu2 — and four yeasts — D. hansenii DH68, G. candidum GC129, Y. lipolytica CI35 and K. lactis\n",
      " KL65. This composition is representative of the diversity of smear soft\n",
      " cheese. The microorganisms were originally isolated from Munster except\n",
      " for Re117 (Reblochon), Com1 (unknown) and FH1 (St. Nectaire). The \n",
      "Gram-negative bacteria studied, P. celer 91 and H. alvei\n",
      " 2 920, isolated from Livarot and Munster cheese, respectively, were \n",
      "chosen from a large cheese bacteria collection for their low level of \n",
      "sanitary risk (sensitivity to 24 antibiotics, no production of biogenic \n",
      "amines in synthetic media and no growth under anaerobic condition and at\n",
      " 37 °C) (Coton et al., 2012).\n",
      "\n",
      "Entities:\n",
      "T1 : {'type': 'Microorganism', 'offsets': [[11, 15], [67, 96]], 'text': 'S3\\xa0+ Lactococcus lactis sp. lactis'}\n",
      "T3 : {'type': 'Microorganism', 'offsets': [[50, 53], [67, 96]], 'text': 'S3- Lactococcus lactis sp. lactis'}\n",
      "T4 : {'type': 'Habitat', 'offsets': [[111, 117]], 'text': 'cheese'}\n",
      "T5 : {'type': 'Habitat', 'offsets': [[166, 181]], 'text': 'model community'}\n",
      "T6 : {'type': 'Microorganism', 'offsets': [[208, 231]], 'text': 'Lactobacillus casei FH1'}\n",
      "T7 : {'type': 'Microorganism', 'offsets': [[233, 264]], 'text': 'Arthrobacter arilaitensis Re117'}\n",
      "T8 : {'type': 'Microorganism', 'offsets': [[266, 293]], 'text': 'Corynebacterium casei Mu120'}\n",
      "T9 : {'type': 'Microorganism', 'offsets': [[295, 314]], 'text': 'C. flavescens Mu128'}\n",
      "T10 : {'type': 'Microorganism', 'offsets': [[316, 334]], 'text': 'C. variabile Mu129'}\n",
      "T11 : {'type': 'Microorganism', 'offsets': [[336, 363]], 'text': 'Staphylococcus xylosus Com1'}\n",
      "T12 : {'type': 'Microorganism', 'offsets': [[368, 382]], 'text': 'S. equorum Mu2'}\n",
      "T13 : {'type': 'Microorganism', 'offsets': [[403, 419]], 'text': 'D. hansenii DH68'}\n",
      "T14 : {'type': 'Microorganism', 'offsets': [[421, 438]], 'text': 'G. candidum GC129'}\n",
      "T15 : {'type': 'Microorganism', 'offsets': [[440, 458]], 'text': 'Y. lipolytica CI35'}\n",
      "T16 : {'type': 'Microorganism', 'offsets': [[463, 478]], 'text': 'K. lactis  KL65'}\n",
      "T17 : {'type': 'Habitat', 'offsets': [[535, 553]], 'text': 'smear soft  cheese'}\n",
      "T18 : {'type': 'Habitat', 'offsets': [[604, 611]], 'text': 'Munster'}\n",
      "T19 : {'type': 'Microorganism', 'offsets': [[624, 629]], 'text': 'Re117'}\n",
      "T20 : {'type': 'Habitat', 'offsets': [[631, 640]], 'text': 'Reblochon'}\n",
      "T21 : {'type': 'Microorganism', 'offsets': [[643, 647]], 'text': 'Com1'}\n",
      "T22 : {'type': 'Microorganism', 'offsets': [[662, 665]], 'text': 'FH1'}\n",
      "T23 : {'type': 'Habitat', 'offsets': [[667, 679]], 'text': 'St. Nectaire'}\n",
      "T25 : {'type': 'Microorganism', 'offsets': [[719, 730]], 'text': 'P. celer 91'}\n",
      "T26 : {'type': 'Microorganism', 'offsets': [[735, 750]], 'text': 'H. alvei  2 920'}\n",
      "T27 : {'type': 'Habitat', 'offsets': [[766, 773]], 'text': 'Livarot'}\n",
      "T28 : {'type': 'Habitat', 'offsets': [[778, 792]], 'text': 'Munster cheese'}\n",
      "T29 : {'type': 'Habitat', 'offsets': [[834, 840]], 'text': 'cheese'}\n",
      "T32 : {'type': 'Habitat', 'offsets': [[968, 983]], 'text': 'synthetic media'}\n",
      "Positive relations:\n",
      "R1 : {'type': 'Lives_In', 'e1': 'T1', 'e2': 'T4', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R2 : {'type': 'Lives_In', 'e1': 'T3', 'e2': 'T4', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R4 : {'type': 'Lives_In', 'e1': 'T6', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R5 : {'type': 'Lives_In', 'e1': 'T6', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R6 : {'type': 'Lives_In', 'e1': 'T7', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R7 : {'type': 'Lives_In', 'e1': 'T7', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R8 : {'type': 'Lives_In', 'e1': 'T8', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R9 : {'type': 'Lives_In', 'e1': 'T8', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R10 : {'type': 'Lives_In', 'e1': 'T8', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R11 : {'type': 'Lives_In', 'e1': 'T9', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R12 : {'type': 'Lives_In', 'e1': 'T9', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R13 : {'type': 'Lives_In', 'e1': 'T9', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R14 : {'type': 'Lives_In', 'e1': 'T10', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R15 : {'type': 'Lives_In', 'e1': 'T10', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R16 : {'type': 'Lives_In', 'e1': 'T10', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R17 : {'type': 'Lives_In', 'e1': 'T11', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R18 : {'type': 'Lives_In', 'e1': 'T11', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R19 : {'type': 'Lives_In', 'e1': 'T11', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R20 : {'type': 'Lives_In', 'e1': 'T12', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R21 : {'type': 'Lives_In', 'e1': 'T12', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R22 : {'type': 'Lives_In', 'e1': 'T12', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R23 : {'type': 'Lives_In', 'e1': 'T13', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R24 : {'type': 'Lives_In', 'e1': 'T13', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R25 : {'type': 'Lives_In', 'e1': 'T13', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R26 : {'type': 'Lives_In', 'e1': 'T14', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R27 : {'type': 'Lives_In', 'e1': 'T14', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R28 : {'type': 'Lives_In', 'e1': 'T14', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R29 : {'type': 'Lives_In', 'e1': 'T15', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R30 : {'type': 'Lives_In', 'e1': 'T15', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R31 : {'type': 'Lives_In', 'e1': 'T15', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R32 : {'type': 'Lives_In', 'e1': 'T16', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R33 : {'type': 'Lives_In', 'e1': 'T16', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R34 : {'type': 'Lives_In', 'e1': 'T16', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R35 : {'type': 'Lives_In', 'e1': 'T19', 'e2': 'T20', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R36 : {'type': 'Lives_In', 'e1': 'T22', 'e2': 'T23', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R37 : {'type': 'Lives_In', 'e1': 'T25', 'e2': 'T32', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R38 : {'type': 'Lives_In', 'e1': 'T25', 'e2': 'T27', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R41 : {'type': 'Lives_In', 'e1': 'T26', 'e2': 'T32', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "R42 : {'type': 'Lives_In', 'e1': 'T26', 'e2': 'T28', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_doc_id = \"BB-rel-F-22177851-006\"\n",
    "print (\"TEXT=\", train[train_doc_id]['text'])\n",
    "print (\"Entities:\")\n",
    "for entity_id in train[train_doc_id]['entities']:\n",
    "  print (entity_id , \":\" , train[train_doc_id]['entities'][entity_id])\n",
    "\n",
    "print (\"Positive relations:\")\n",
    "for positive_relation_id in train[train_doc_id]['relations']:\n",
    "  print(positive_relation_id, \":\" , train[train_doc_id]['relations'][positive_relation_id])\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a function that can tag entity spans, based on entity types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('text', '[The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author\\'s transl)].\\n\\n')\n",
      "('entities', {'T2': {'type': 'Microorganism', 'offsets': [[22, 30]], 'text': 'Serratia'}, 'T3': {'type': 'Habitat', 'offsets': [[39, 68]], 'text': 'Hospital S. Camillo De Lellis'}, 'T4': {'type': 'Geographical', 'offsets': [[72, 76]], 'text': 'Roma'}, 'T5': {'type': 'Geographical', 'offsets': [[78, 83]], 'text': 'Italy'}})\n",
      "('relations', {'R1': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}, 'R2': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T3', 'e1_type': 'Microorganism', 'e2_type': 'Location'}, 'R3': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T4', 'e1_type': 'Microorganism', 'e2_type': 'Location'}})\n",
      "--------------------------------------------------------------------------------\n",
      "ORIGINAL TEXT :   [The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author's transl)].\n",
      "\n",
      "\n",
      "ENCODED TEXT :    [The infections from \"<Microorganism>Serratia</Microorganism>\" in the <Habitat>Hospital S. Camillo De Lellis</Habitat> of <Geographical>Roma</Geographical> (<Geographical>Italy</Geographical>) (author's transl)].\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def mark_entities_with_entity_tags(text, entities):\n",
    "    \"\"\"\n",
    "    Annotate text with XML-like tags inserted directly into the text.\n",
    "\n",
    "    For each entity we assume the structure:\n",
    "      { \"type\": , \"offsets\": [[start, end]], \"text\": <...> }\n",
    "\n",
    "    Overlapping annotations will be handled by inserting tags at the boundaries.\n",
    "    (If spans cross rather than nest, the output may have crossing tags; in many\n",
    "    applications you would split such spans to get a well-formed nesting.)\n",
    "\n",
    "    Returns:\n",
    "      A new string with opening and closing tags inserted.\n",
    "      For example: experimental smear soft cheese\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    # For each entity (each value in the dictionary) add a start event and an end event.\n",
    "    for ent in entities.values():\n",
    "        tag = ent[\"type\"]\n",
    "        for start, end in ent[\"offsets\"]:\n",
    "            # Save event as (position, event_type, auxiliary, tag)\n",
    "            # For a start event, we record the end position as auxiliary (so we can sort descending by end)\n",
    "            # For an end event, we record the start position (so we can sort ascending by start).\n",
    "            events.append((start, \"start\", end, tag))\n",
    "            events.append((end, \"end\", start, tag))\n",
    "\n",
    "    # Define a sort key so that:\n",
    "    #   - Primary: sort by position.\n",
    "    #   - At the same position, \"end\" events come before \"start\" events.\n",
    "    #   - For start events at the same position, those with later (higher) end come first (so that outer tags open first).\n",
    "    #   - For end events at the same position, those with earlier start come first.\n",
    "    def event_sort_key(e):\n",
    "        pos, etype, aux, tag = e\n",
    "        if etype == \"end\":\n",
    "            return (pos, 0, aux)  # lower auxiliary value first\n",
    "        else:  # \"start\"\n",
    "            return (pos, 1, -aux)  # higher aux (later end) first\n",
    "\n",
    "    events.sort(key=event_sort_key)\n",
    "\n",
    "    # Now, we iterate over the sorted events and insert tag strings at the appropriate positions.\n",
    "    # We'll build a list of (position, string_to_insert) items.\n",
    "    inserts = []\n",
    "    for pos, etype, aux, tag in events:\n",
    "        if etype == \"end\":\n",
    "            inserts.append((pos, f\"</{tag}>\"))\n",
    "        else:\n",
    "            inserts.append((pos, f\"<{tag}>\"))\n",
    "\n",
    "    # Because multiple inserts may occur at the same position, group them.\n",
    "    # We already sorted events so that the insertions are in the correct order.\n",
    "    # Now, build the annotated text by iterating through the text and inserting tags at the right offsets.\n",
    "    result = []\n",
    "    last_index = 0\n",
    "    for pos, insert_text in inserts:\n",
    "        # Append the text between the last index and current position.\n",
    "        if pos > last_index:\n",
    "            result.append(text[last_index:pos])\n",
    "        # Append the tag.\n",
    "        result.append(insert_text)\n",
    "        last_index = pos\n",
    "    # Append any remaining text.\n",
    "    result.append(text[last_index:])\n",
    "    return \"\".join(result)\n",
    "\n",
    "train_doc_id = \"BB-rel-607884\"\n",
    "for item in train[train_doc_id].items():\n",
    "  print (item)\n",
    "\n",
    "print (\"-\"*80)\n",
    "text = train[train_doc_id]['text']\n",
    "entities = train[train_doc_id]['entities']\n",
    "print (\"ORIGINAL TEXT :  \", text)\n",
    "print (\"ENCODED TEXT :   \", mark_entities_with_entity_tags(text, entities))\n",
    "print (\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are two possibilities now:**\n",
    " 1. Marking full texts with all entities, and asking GPT to extract all possible relations Lives_in(Microorganism, Habitat/Geographical), and hope for the best. But then we will need to process the output for an accurate evaluation, **which can get tricky.**\n",
    " 2. Generative all possible positive and negative pairs, assign them unique relation id, then feeding each example separately to GPT (or pack them together), and asking for predicting the label to be positive or negative.\n",
    "\n",
    "Here is the second approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UID': 'UID_3158', 'doc_id': 'BB-rel-607884', 'e1': 'T2', 'e2': 'T3', 'text': '[The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author\\'s transl)].\\n\\n', 'marked_text': '[The infections from \"<Microorganism>Serratia</Microorganism>\" in the <Habitat>Hospital S. Camillo De Lellis</Habitat> of Roma (Italy) (author\\'s transl)].\\n\\n', 'label': 'Positive'}\n",
      "{'UID': 'UID_3159', 'doc_id': 'BB-rel-607884', 'e1': 'T2', 'e2': 'T4', 'text': '[The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author\\'s transl)].\\n\\n', 'marked_text': '[The infections from \"<Microorganism>Serratia</Microorganism>\" in the Hospital S. Camillo De Lellis of <Geographical>Roma</Geographical> (Italy) (author\\'s transl)].\\n\\n', 'label': 'Positive'}\n",
      "{'UID': 'UID_3160', 'doc_id': 'BB-rel-607884', 'e1': 'T2', 'e2': 'T5', 'text': '[The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author\\'s transl)].\\n\\n', 'marked_text': '[The infections from \"<Microorganism>Serratia</Microorganism>\" in the Hospital S. Camillo De Lellis of Roma (<Geographical>Italy</Geographical>) (author\\'s transl)].\\n\\n', 'label': 'Positive'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def generate_and_mark_all_candidate_pairs(_dataset):\n",
    "  unique_relation_id_index = 0\n",
    "  results = []\n",
    "  for document_id in _dataset:\n",
    "    text = _dataset[document_id]['text']\n",
    "    entities = _dataset[document_id]['entities']\n",
    "    ent_microorganisms = [e_id for e_id in entities if entities[e_id]['type'] == \"Microorganism\"]\n",
    "    ent_locations = [e_id for e_id in entities if entities[e_id]['type'] in [\"Geographical\", \"Habitat\"]]\n",
    "    # generate all possible pairs\n",
    "    candidate_pairs = list(product(ent_microorganisms, ent_locations))\n",
    "\n",
    "    # look at relations to get information about all positive pairs\n",
    "    relations = _dataset[document_id]['relations']\n",
    "    positive_pairs = (relations.items())\n",
    "    positive_pairs = set([(b['e1'], b['e2']) for (a, b) in relations.items()])\n",
    "\n",
    "    for (a, b) in candidate_pairs:\n",
    "      this_example_entities = dict()\n",
    "      this_example_entities[a] = entities[a]\n",
    "      this_example_entities[b] = entities[b]\n",
    "      if (a, b) in positive_pairs:\n",
    "        this_example_label = \"Positive\"\n",
    "      else:\n",
    "        this_example_label = \"Negative\"\n",
    "\n",
    "      ml_example = {\"UID\" : \"UID_\" + str(unique_relation_id_index),\n",
    "                    \"doc_id\": document_id,\n",
    "                    \"e1\" : a ,\n",
    "                    \"e2\" : b ,\n",
    "                    \"text\": text,\n",
    "                    \"marked_text\": mark_entities_with_entity_tags(text, this_example_entities),\n",
    "                    \"label\": this_example_label}\n",
    "      results.append(ml_example)\n",
    "      unique_relation_id_index += 1\n",
    "  return results\n",
    "\n",
    "train_examples = generate_and_mark_all_candidate_pairs(train)\n",
    "devel_examples = generate_and_mark_all_candidate_pairs(devel)\n",
    "\n",
    "for example in train_examples:\n",
    "  if example['doc_id'] == \"BB-rel-607884\":\n",
    "    print(example)\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another document with id = BB-rel-F-22177851-000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('text', 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n')\n",
      "('entities', {'T2': {'type': 'Microorganism', 'offsets': [[62, 81]], 'text': 'Psychrobacter celer'}, 'T3': {'type': 'Microorganism', 'offsets': [[86, 98]], 'text': 'Hafnia alvei'}, 'T4': {'type': 'Habitat', 'offsets': [[132, 187]], 'text': 'microbial community of an experimental smear soft chees'}, 'T5': {'type': 'Habitat', 'offsets': [[158, 188]], 'text': 'experimental smear soft cheese'}})\n",
      "('relations', {'R2': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}, 'R4': {'type': 'Lives_In', 'e1': 'T3', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}})\n",
      "----------------------------------------\n",
      "{'UID': 'UID_856', 'doc_id': 'BB-rel-F-22177851-000', 'e1': 'T2', 'e2': 'T4', 'text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n', 'marked_text': 'Ecological and aromatic impact of two Gram-negative bacteria (<Microorganism>Psychrobacter celer</Microorganism> and Hafnia alvei) inoculated as part of the whole <Habitat>microbial community of an experimental smear soft chees</Habitat>e\\n', 'label': 'Negative'}\n",
      "{'UID': 'UID_857', 'doc_id': 'BB-rel-F-22177851-000', 'e1': 'T2', 'e2': 'T5', 'text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n', 'marked_text': 'Ecological and aromatic impact of two Gram-negative bacteria (<Microorganism>Psychrobacter celer</Microorganism> and Hafnia alvei) inoculated as part of the whole microbial community of an <Habitat>experimental smear soft cheese</Habitat>\\n', 'label': 'Positive'}\n",
      "{'UID': 'UID_858', 'doc_id': 'BB-rel-F-22177851-000', 'e1': 'T3', 'e2': 'T4', 'text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n', 'marked_text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and <Microorganism>Hafnia alvei</Microorganism>) inoculated as part of the whole <Habitat>microbial community of an experimental smear soft chees</Habitat>e\\n', 'label': 'Negative'}\n",
      "{'UID': 'UID_859', 'doc_id': 'BB-rel-F-22177851-000', 'e1': 'T3', 'e2': 'T5', 'text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n', 'marked_text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and <Microorganism>Hafnia alvei</Microorganism>) inoculated as part of the whole microbial community of an <Habitat>experimental smear soft cheese</Habitat>\\n', 'label': 'Positive'}\n"
     ]
    }
   ],
   "source": [
    "for item in train[\"BB-rel-F-22177851-000\"].items():\n",
    "  print (item)\n",
    "print (\"-\"*40)\n",
    "for example in train_examples:\n",
    "  if example['doc_id'] == \"BB-rel-F-22177851-000\":\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look how many positive and negative examples are in the devel set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
